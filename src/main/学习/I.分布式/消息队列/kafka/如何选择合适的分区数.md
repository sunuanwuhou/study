# Table of Contents

* [分区过多的弊端](#分区过多的弊端)
* [如何确定?](#如何确定)


Kafka高吞吐量的原因之一就是通过partition将topic中的消息保存到Kafka集群中不同的broker中。

无论是Kafka的producer，还是consumer都可以并发操作topic中的partition，因此partition是Kafka并行度调优的最小单元。

**理论上说，如果一个topic分区越多，理论上整个集群所能达到的吞吐量就越大。**

但是，实际生产中Kafka topic的分区数真的配置越多越好吗？很显然不是！

# 分区过多的弊端

分区数过多会有以下弊端

1. 客户端/服务器端需要使用的内存就越多

+ 生产者是productBatch缓存消息的，分区越多，所需要的内存越多
+ 消费者消费是需要开启线程的。分区越多。线程开销也不小

2. 文件句柄的开销

   在Kafka的broker中，每个partition都会对应磁盘文件系统的一个目录。在Kafka的数据日志文件目录中，每个日志数据段都会分配两个文件，一个索引文件和一个数据文件。当前版本的kafka，每个broker会为每个日志段文件打开一个index文件句柄和一个数据文件句柄。因此，随着partition的增多，所需要保持打开状态的文件句柄数也就越多，最终可能超过底层操作系统配置的文件句柄数量限制。

3. 端对端的延迟

   其实就是AR副本之间的复制需要时间

4. 降低高可用

   分区一多，一旦broker宕机，后果就很难受了。

# 如何确定?

合适的partition数量可以达到高度并行读写和负载均衡的目的，**需要根据每个分区的生产者和消费者的目标吞吐量进行估计**。

可以遵循一定的步骤来确定分区数：根据某个topic日常"接收"的数据量等经验确定分区的初始值，然后测试这个topic的producer吞吐量和consumer吞吐量。假设它们的值分别是Tp和Tc，单位可以是MB/s。

然后假设总的目标吞吐量是Tt，那么

> numPartitions = Tt / max(Tp, Tc)


如果一定要给一个准则，则建议将分区数设定为集群中broker的倍数，即假定集群中有3个broker节点，可以设定分区数为3、6、9等，至于倍数的选定可以参考预估的吞吐量。
